<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Jiesong Bai, Bai Jiesong, SHU, Shanghai University"> 
<meta name="description" content="Baijiesong's Home">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Jiesong Bai@SHU</title>
<style>
    .smaller-image {
      width: 20%;
    }
</style>


</head>
<body>
<div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/baijiesong" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Jiesong Bai(ÁôΩÊ¥ÅÊùæ) </h1>
					<h1></h1>
					</div>
				<h3>Incoming Phd Student@SJTU</h3>
				<p>
					Shanghai University <br>
					Shanghai.<br>
					<br>
					Email: jiesongbai.7 [at] gmail.com<br>
				</p>
				<p> <a href="https://scholar.google.cz/citations?user=RcmacakAAAAJ&hl=zh-CN"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/baijiesong"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
				</p>
			</td>
			<td>
				<img src="./pic/my.png" border="0" width="240"><br>
			</td>
		</tr><tr>
	</tr></tbody>
</table>

<h2>Biography</h2>
<p>
	I am a 4th-year undergraduate student majoring in Communication Engineering at <a href="https://www.shu.edu.cn/">Shanghai University (SHU)</a>, and I hope to receive my Bachelor's degree in July 2025. 
	I also fortunately become a incoming PhD Student studied in the <a href="https://min.sjtu.edu.cn/">MIN@SJTU</a> led by Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&user=bB16iN4AAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Dr. Hongkai Xiong</a></a>.
	Currently, I am doing research here, supervised by Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&user=Xg8MhyAAAAAJ">Wenrui Dai</a>
</p>
<p>My research interests include <b>Deep Learning</b> and  <b>AI System</b>. From 2023, I started to do some research on Computer Vision, including talking head generation and low level vision. Now, 
	I'm starting to explore the research related to distributed training cluster optimization, mainly foucs on Collective Communication.
	And I'm also interested in some LLM and AIGC Applications.</p>

<p><i style="color: red; display: inline;">Feel free to contact me by email if you are interested in discussing or collaborating with me.</i></p>


<h2>News</h2>
<div style="height: 240px; overflow: auto;">
<ul>
	<li>
		[10/2024] Awarded National Scholarship in <a herf="https://scie.shu.edu.cn/info/1065/42915.htm">the first place</a> in the <a herf="https://scie.shu.edu.cn/">SCIE@SHU</a> !
	</li>
	<li>
		[09/2024] I fortunately become a incoming PhD Student@SJTU, supervised by Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&user=bB16iN4AAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Hongkai Xiong</a> !
	</li>
	<li>
		[08/2024] One paper is accepted by <a href="https://iconip2024.org/">ICONIP 2024</a> !  
	</li>
	<li>
		[06/2024] Excited to release <i style="color: red; display: inline;">RetinexMamba's</i> Code with collaborator <a href="https://github.com/YhuoyuH">Yuhao Yin</a>. Code Repo here <a href="https://github.com/YhuoyuH/RetinexMamba"> RetinexMamba</a>  !
	</li>
	<li>
		[05/2024] Fortunately be invited to be a reviewer for <a href="https://cis.ieee.org/publications/ieee-transactions-on-artificial-intelligence">IEEE Transactions on Artificial Intelligence</a>!
	</li>
	<li>
		[11/2023] Awarded Outstanding School's Scholarship of <a herf="https://www.shu.edu.cn/">Shanghai University</a> !
	</li>
	<li>
		[07/2023] I start to do some research on talking head generation(SHU's Outstanding Undergraduate Project) !
	</li>
	<li>
		[11/2022] Awarded Outstanding School's Scholarship of <a herf="https://www.shu.edu.cn/">Shanghai University</a> !
	</li>
	<li>
		[09/2022] Joined <a href="https://scie.shu.edu.cn/info/1065/42915.htm">SCIE@SHU</a>!
	</li>
	<li>
		[09/2021] Started my first undergraduate year in <a herf="https://www.shu.edu.cn/">Shanghai University</a>!
	</li>
</ul>
</div>

<h2>Industrial Experience</h2>
<table id="tbPublications" width="100%">
	<tbody>
</tbody></table>


<h2>Education & Visiting</h2>
<table id="tbPublications" width="100%">
	<tbody>
		<td width="306">
		<img src="./education/sjtu.png" width="270px" style="box-shadow: 4px 4px 8px #ffffff">
		</td>				
		<td>
		<p><b>Shanghai Jiao Tong University, Shanghai</b></p>
		<p>Incoming PhD Student in MIN, SJTU </p>
		<p>Advisor: <a href="https://ee.sjtu.edu.cn/FacultyDetail.aspx?id=93&infoid=66&flag=66">Prof. Hongkai Xiong</a> </p>
		<p>Sep. 2025 - Future <p>
		</p>
		</td>
	</tr>
	<!--########################-->
	<tr>
		<tr>
			<td width="306">
			<img src="./education/shu.png" width="270px" style="box-shadow: 4px 4px 8px #ffffff">
			</td>				
			<td>
			<p><b>Shanghai University, Shanghai</b></p>
			<p>Bachelor of Engineering in Communication Engineering </p>
			<p>Sep. 2021 - Jul. 2025(expected) <p>
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>

	<!--########################-->
		
</tbody></table>

<h2> Selected Publications | <a href="https://scholar.google.com/citations?user=kwBR1ygAAAAJ&hl=zh-CN">Full List</a></h2>
<!--
<div style="height: 1440px; overflow: auto;">
-->
<table id="tbPublications" width="100%">
	<tbody>
	<td><b>/*Preprints*/</b>
	<p></p>
	</td>
	<tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
<tr>
		<td width="306">
		<img src="./indexpics/2024-Fypv2.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Follow-Your-Pose v2: Multiple-Condition Guided Character Image Animation for Stable Pose Control</b></p>
		<p>Jingyun Xue, Hongfa Wang, Qi Tian, <b>Yue Ma</b>, Andong Wang, Zhiyuan Zhao, Shaobo Min, Wenzhe Zhao, Kaihao Zhang, Heung-Yeung Shum, Wei Liu, Mengyang Liu, Wenhan Luo</p>
		<em>arXiv preprint:2406.03035. 2024</em>
		<p> [<a href="hhttps://arxiv.org/abs/2406.03035">paper</a>] [<a href="https://github.com/mayuelala">code</a>] [<a href="https://github.com/mayuelala">project page</a>] 
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<tr>
			<td width="306">
			<img src="./indexpics/2024-Canvas.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>				
			<td>
			<p><b>Follow-Your-Canvas: Higher-Resolution Video Outpainting with Extensive Content Generation</b></p>
			<p>Qihua Chen*, <b>Yue Ma*</b>, Hongfa Wang*, Junkun Yuan*, Wenzhe Zhao, Qi Tian, Hongmei Wang, Shaobo Min, Qifeng Chen, Wei Liu</p>
			<em>arXiv preprint:2409.01055. 2024</em>
			<p> [<a href="hhttps://arxiv.org/abs/2409.01055">paper</a>] [<a href="https://github.com/mayuelala">code</a>] [<a href="https://github.com/mayuelala">project page</a>] 
			</p>
			</td>
		</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<tr>
			<td width="306">
			<img src="./indexpics/2024-multiBooth.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>				
			<td>
			<p><b>MultiBooth: Towards Generating All Your Concepts in an Image from Text</b></p>
			<p>Chenyang Zhu, Kai Li, <b>Yue Ma</b>, Chunming He, Xiu Li</p>
			<em>arXiv preprint:2404.14239. 2024</em>
			<p> [<a href="hhttps://arxiv.org/abs/2404.14239">paper</a>] [<a href="https://github.com/mayuelala">code</a>] [<a href="https://github.com/mayuelala">project page</a>] 
			</p>
			</td>
		</tr>
		<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="./indexpics/2024-followyourclick.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts</b></p>
		<p><b>Yue Ma</b>, Yingqing He, Hongfa Wang, Andong Wang, Chenyang Qi, Chengfei Cai, Xiu Li, Zhifeng Li, Heung-Yeung Shum, Wei Liu, Qifeng Chen</p>
		<em>arXiv preprint:2403.08268. 2024</em>
		<p> [<a href="https://arxiv.org/abs/2403.08268">paper</a>] [<a href="https://github.com/mayuelala/FollowYourClick">code</a>] [<a href="https://follow-your-click.github.io/">project page</a>] 
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>

	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2022-simvtp-framework.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>SimVTP: Simple Video Text Pre-training with Masked Autoencoders</b></p>
		<p><b>Yue Ma</b>, Tianyu Yang, Ying Shan, Xiu Li</p>
		<em>arXiv preprint:2211.03490. 2022</em>
		<p> [<a href="https://arxiv.org/pdf/2211.03490">paper</a>] [<a href="https://github.com/mayuelala/SimVTP">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->

	<td><b>/*Journal*/</b>
		<p></p>
		</td>
		
		<tr>
			<td width="306">
			<img src="./indexpics/2023-TMM-mmlab.png" width="285px" style="box-shadow: 4px 4px 8px #888">
			</td>				
			<td>
			<p><b>Attentive Snippet Prompting for Video Retrieval</b></p>
			<p>Siran Chen, Qinglin Xu, <b>Yue Ma</b>, Yu Qiao, Yali Wang</p>
			<em>IEEE Transactions on Multimedia (<b>TMM</b>), 2024. </em>
			<i></i>
			<p> [<a href="https://ieeexplore.ieee.org/abstract/document/10268993/">paper</a>] [<a href="https://ieeexplore.ieee.org/abstract/document/10268993/">code</a>] </p>
			</td>
		</tr>
		<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>
			<tr>&nbsp</tr>

	<!--########################-->
		
	<td><b>/*Conference*/</b>
	<p></p>
	</td>
	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2023-MagicStick.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>MagicStickü™Ñ: Controllable Video Editing via Control Handle Transformations</b></p>
		<p><b>Yue Ma</b>, Xiaodong Cun, Yingqing He, Chenyang Qi, Xintao Wang, Ying Shan, Xiu Li, Qifeng Chen</p>
		<em>IEEE /CVF Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2025</em>
		<p> [<a href="https://arxiv.org/abs/2312.03047">paper</a>] [<a href="https://github.com/mayuelala/MagicStick">code</a>] [<a href="https://magic-stick-edit.github.io/">project page</a>] 
		</p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->
	<tr></tr>
		<td width="306">
		<img src="./indexpics/2024-followyouremoji.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation</b></p>
		<p><b>Yue Ma</b>, Hongyu Liu, Hongfa Wang, Heng Pan, Yingqing He, Junkun Yuan, Ailing Zeng, Chengfei Cai, Heung-Yeung Shum, Wei Liu, Qifeng Chen</p>
		<em>The ACM Special Interest Group for Computer Graphics and Interactive Techniques(<b>Siggraph Asia</b>) 2024</em>
		<p> [<a href="https://arxiv.org/abs/2406.01900">paper</a>] [<a href="https://github.com/mayuelala">code</a>] [<a href="https://follow-your-emoji.github.io/">project page</a>] 
		</p>
		</td>
	</tr>
	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2024-cove.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>COVE: Unleashing the Diffusion Feature Correspondence for Consistent Video Editing</b></p>
		<p>Jiangshan Wang*, <b>Yue Ma*</b>, Jiayi Guo*, Yicheng Xiao, Gao Huang, Xiu Li</p>
		<em>Conference on Neural Information Processing Systems(<b>NeurIPS</b>). 2024</em>
		<p> [<a href="https://arxiv.org/abs/2406.08850">paper</a>] [<a href="https://github.com/mayuelala">code</a>] [<a href="https://cove-video.github.io/">project page</a>] 
		</p>
		</td>
	</tr>
	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2024-ACMMM.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Freehand Sketch Generation from Mechanical Components</b></p>
		<p>Zhichao Liao, Di Huang, Heming Fang, <b>Yue Ma</b>, Fengyuan Piao, Xinghui Li, Long Zeng, Pingfa Feng</p>
		<em>The 32th ACM International Conference on Multimedia. (<b>ACM MM</b>), 2024.</em>
		<p> [<a href="https://arxiv.org/abs/2406.08850">paper</a>] [<a href="https://github.com/mayuelala">code</a>] [<a href="https://cove-video.github.io/">project page</a>] 
		</p>
		</td>
	</tr>
	<!--########################-->
	 <tr>
		<td width="306">
		<img src="./indexpics/2023-bridge.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Bridging the Gap: A Unified Video Comprehension Framework for Moment Retrieval and Highlight Detection</b></p>
		<p>Yicheng Xiao, Zhuoyan Luo, Yong Liu, <b>Yue Ma</b>, Hengwei Bian, Yatai Ji, Yujiu Yang, Xiu Li</p>
		<em>IEEE /CVF Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024</em>
		<p> [<a href="https://arxiv.org/abs/2311.16464">paper</a>] [<a href="https://github.com/EasonXiao-888/UVCOM">code</a>] [<a href="https://github.com/EasonXiao-888/UVCOM">project page</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2023-iccv-followyourpose.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>üï∫üï∫üï∫ Follow-Your-Pose üíÉüíÉüíÉ: Pose-Guided Text-to-Video Generation using Pose-Free Videos</b></p>
		<p><b>Yue Ma</b>, Yingqing He, Xiaodong Cun, Xintao Wang, Siran Chen, Ying Shan, Xiu Li, Qifeng Chen</p>
		<em>The 38th Annual AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2024</em>
		<p> [<a href="https://arxiv.org/abs/2304.01186">paper</a>] [<a href="https://github.com/mayuelala/FollowYourPose">code</a>] [<a href="https://follow-your-pose.github.io/">project page</a>] 
		<a target="_blank" href ="https://github.com/mayuelala/FollowYourPose"><img alt="GitHub stars" align="right" src="https://img.shields.io/github/stars/mayuelala/FollowYourPose?style=social"></a></p>
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<!--########################-->
	<tr>
		<td width="306">
		<img src="./indexpics/2024-AAAI-MBEV.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>M-BEV: Masked BEV Perception for Robust Autonomous Driving</b></p>
		<p>Siran Chen, <b>Yue Ma</b>, Yu Qiao, Yali Wang</p>
		<em>The 38th Annual AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2024</em>
		<p> [<a href="https://arxiv.org/abs/2304.01186">paper</a>] [<a href="https://github.com/mayuelala/FollowYourPose">code</a>] [<a href="https://follow-your-pose.github.io/">project page</a>] 
		</td>
	</tr>
	<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
		<tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="./indexpics/2023-icassp-audio.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>SemanticAC: Semantics-Assisted Framework for Audio Classification</b></p>
		<p>Yicheng Xiao*, <b>Yue Ma*</b>, Shuyan Li, Hantao Zhou, Ran Liao, Xiu Li (* equal contribution)</p>
		<em>IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>), 2023. </em>
		<i></i>
		<p> [<a href="https://arxiv.org/abs/2302.05940">paper</a>] [<a href="https://github.com/mayuelala">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>&nbsp</tr>
	<tr>
		<td width="306">
		<img src="./indexpics/2022-mm-graph.png" width="285px" style="box-shadow: 4px 4px 8px #888">
		</td>				
		<td>
		<p><b>Visual Knowledge Graph for Human Action Reasoning in Videos</b></p>
		<p><b>Yue Ma</b>, Yali Wang, Yue Wu, Ziyu Lyu, Siran Chen, Xiu Li, Yu Qiao</p>
		<em>The 30th ACM International Conference on Multimedia. (<b>ACM MM</b>), 2022. </em>
		<i><p style="color: red; display: inline;">(Oral Presentation)</p></i>
		<p> [<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548257">paper</a>] [<a href="https://github.com/mayuelala/AKU">code</a>] </p>
		</td>
	</tr>
	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
    	<tr>&nbsp</tr>
		


</tbody></table>
<!--
</div>
-->




<h2>Honors &amp; Awards</h2>
<table style="border-spacing:2px">
	<tbody>
	<tr><td> [06/2024] Outstanding graduates student of Beijing.</td></tr>
	<tr><td> [08/2023] First-Class Scholarship of <a herf="https://www.tsinghua.edu.cn/">Tsinghua University</a>.</td></tr>
	<tr><td> [12/2022] First-Class Scholarship of <a herf="https://www.tsinghua.edu.cn/">SIGS</a>, Tsinghua University.</td></tr>
	<tr><td> [03/2022] <a href="https://www.withzz.com/project/detail/99">Tencent Rhino-Bird Research Elite Program</a>, only 72 students in the world admitted to this program.</td></tr>
	<tr><td> [09/2020] Scholarship for Academic Excellence of <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a>.</td></tr>.
	<tr><td> [06/2019] Excellent Scientific Student of <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a>.</td></tr>.
	<tr><td> [09/2019] Scholarship for Academic Excellence of <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a>.</td></tr>
	<tr><td> [09/2018] Excellent Academic Progress Student of <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a>.</td></tr>.
	<tr><td> [06/2018] Scholarship for Academic Excellence of <a href="http://ccst.tyut.edu.cn/">Taiyuan University of Technology</a>.</td></tr>.

	</tbody>
</table>


<h2>Professional Services</h2>
<ul>
	<li>	
	<b>Student Reviewers:</b><br>
	Computer Vision and Pattern Recognition (CVPR)<br>
	International Conference on Computer Vision (ICCV)<br>
	European Conference on Computer Vision (ECCV)<br>
	Conference and Workshop on Neural Information Processing Systems (NeurIPS)<br>
	International Conference on Learning Representations (ICLR) <br>
	AAAI Conference on Artificial Intelligence (AAAI)<br>
	IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
	</li>


</ul>


<h2>Teaching</h2>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> 2022-2023</td><td>Fall</td><td>Artificial Intelligence Technology (THU, 85990263-200)</td>
		</tr>
	</tbody>
</table>




<div id="footer">
	<div id="footer-text"></div>
</div>
	<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=777777&w=487&t=tt&d=xeJu_Kwek6AfO5eDCKFQ1iDWjzFQPLT_dNcYY3WLmrY&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=5b1717'></script>
	<p><center> &copy; Jack Ma </center></p>


</div>
</body></html>
